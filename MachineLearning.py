# -*- coding: utf-8 -*-
"""finalimplementaion2.ipyn

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1S0Dmzb8q5IWhei7EbdN_pYa3EytKj-js
"""

# Mount the Google Drive
from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import re
from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt

# Load the dataset
df = pd.read_csv('/content/drive/MyDrive/EcomDataSet/b2csalesmaster.csv')

# Convert date column to datetime format
df['B2CSalesMaster_OrderDate'] = pd.to_datetime(df['B2CSalesMaster_OrderDate'], infer_datetime_format=True)
df['B2CSalesMaster_OrderDate'] = pd.to_datetime(df['B2CSalesMaster_OrderDate'], format='%d %B %Y')

# Extract year from date column
df['Year'] = df['B2CSalesMaster_OrderDate'].dt.year

# Create a new dataframe with year and total sales
df['B2CSalesMaster_SoldAmount'] = df['B2CSalesMaster_SoldAmount'].str.replace('₹', '').str.replace(',', '').astype(float)
yearly_sales = df.groupby('Year')['B2CSalesMaster_SoldAmount'].sum().reset_index()

# Split data into training and testing sets
X_train = yearly_sales['Year'].values.reshape(-1, 1)
y_train = yearly_sales['B2CSalesMaster_SoldAmount'].values.reshape(-1, 1)

if yearly_sales.shape[0] > 1:
    # Create linear regression model and fit to training data
    lr_model = LinearRegression()
    lr_model.fit(X_train, y_train)

    # Predict sales for the next 5 years
    next_years = np.array([[yearly_sales['Year'].max()+i] for i in range(1,6)])
    predicted_sales = lr_model.predict(next_years)
    predicted_sales = predicted_sales / 1000000
    
    # Plot actual and predicted sales
    plt.plot(X_train, y_train / 1000000, label='Actual Sales')
    plt.plot(next_years, predicted_sales, label='Predicted Sales')
    plt.xlabel('Year')
    plt.ylabel('Sales (in millions)')
    plt.legend()
    plt.show()

else:
    predicted_sales = yearly_sales.iloc[-1, -1]

print('Predicted sales for next 5 years (in millions):')
for year, sales in zip(range(yearly_sales['Year'].max()+1, yearly_sales['Year'].max()+6), predicted_sales):
    print(year, ':', round(float(sales), 2))

import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
import seaborn as sns
import matplotlib.pyplot as plt

# Remove rows with missing data
df.dropna(inplace=True)

# Create a new column for price ranges
df['PriceRange'] = pd.cut(df['B2CSalesMaster_SoldAmount'], bins=[0, 499, 599, 699, 799, np.inf], labels=['< 499', '499-599', '600-699', '700-799', '>= 800'])

# Fit KMeans model
kmeans = KMeans(n_clusters=5, random_state=0).fit(df[['B2CSalesMaster_SoldAmount']])

# Add cluster labels to DataFrame
df['Cluster'] = kmeans.labels_

# Group by cluster and price range
grouped_df = df.groupby(['Cluster', 'PriceRange']).size().reset_index(name='Count')

# Pivot table to wide format
table = grouped_df.pivot(index='Cluster', columns='PriceRange', values='Count')

# Calculate cluster distribution by price range
cluster_dist = pd.crosstab(df['Cluster'], df['PriceRange'])

# Print table
table = cluster_dist.to_string()
print(table)

# Visualize cluster distribution by price range
sns.heatmap(cluster_dist, annot=True, cmap='YlGnBu')
plt.title('Cluster Distribution by Price Range')
plt.xlabel('Price Range')
plt.ylabel('Cluster')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.compose import make_column_transformer
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder

# Load the dataset
df = pd.read_csv('/content/drive/MyDrive/EcomDataSet/b2csalesmaster.csv')

# select columns to use as features and target
features = ['B2CSalesMaster_SoldQty', 'B2CSalesMaster_SoldAmount', 'B2CSalesMaster_OrderPurchaseCost']
target = 'B2CSalesMaster_OrderStatus'

# remove the currency symbol and any other unwanted characters
df['B2CSalesMaster_SoldAmount'] = df['B2CSalesMaster_SoldAmount'].str.replace('₹', '').str.replace(',', '').astype(float)
df['B2CSalesMaster_OrderPurchaseCost'] = df['B2CSalesMaster_OrderPurchaseCost'].str.replace('₹', '').str.replace(',', '').str.replace('-', '').astype(float)

# convert the problematic columns to a numeric format
df['B2CSalesMaster_SoldQty'] = pd.to_numeric(df['B2CSalesMaster_SoldQty'])

# split data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.2, random_state=42)

# create random forest classifier
rfc = RandomForestClassifier(random_state=42)

# fit random forest classifier to training data
rfc.fit(X_train, y_train)

# predict on test data
y_pred = rfc.predict(X_test)

# Evaluate Random Forest Classifier on test data
score = rfc.score(X_test, y_test)
print(f"Accuracy: {score:.2f}")

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

# Get the predicted and true labels
y_pred = rfc.predict(X_test)
labels = np.unique(y_test)

# Compute the confusion matrix
cm = confusion_matrix(y_test, y_pred, labels=labels)

# Plot the confusion matrix
fig, ax = plt.subplots()
im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
ax.figure.colorbar(im, ax=ax)
ax.set(xticks=np.arange(cm.shape[1]),
       yticks=np.arange(cm.shape[0]),
       xticklabels=labels, yticklabels=labels,
       title='Confusion matrix',
       ylabel='True label',
       xlabel='Predicted label')

# Rotate the tick labels and set their alignment
plt.setp(ax.get_xticklabels(), rotation=45, ha="right",
         rotation_mode="anchor")

# Loop over data dimensions and create text annotations
fmt = 'd'
thresh = cm.max() / 2.
for i in range(cm.shape[0]):
    for j in range(cm.shape[1]):
        ax.text(j, i, format(cm[i, j], fmt),
                ha="center", va="center",
                color="white" if cm[i, j] > thresh else "black")

fig.tight_layout()
plt.show()

